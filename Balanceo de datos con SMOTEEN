pip install gdown
pip install pandas
pip install imblearn
------------------------------------------------------------------------------------------------------------------------------------------------------------------
import gdown
import pandas as pd
import os

# ID del archivo de Google Drive
file_id = '1z7UUXiWAvR2D4XvdcfXzkhafU2km4HM-'
# URL de descarga directa
url = f'https://drive.google.com/uc?export=download&id={file_id}'

# Ruta de destino en el nuevo disco montado
output_path = '/mnt/mydisk/BBDD_FRAUDE_PREPROCESADA_VARIABLES_DEF.csv'

# Descargar el archivo
gdown.download(url, output_path, quiet=False)

# Verificar que el archivo se ha descargado correctamente
if os.path.exists(output_path):
    print("El archivo se ha descargado correctamente en", output_path)
    
    # Leer el archivo CSV en un DataFrame de pandas
    bbdd = pd.read_csv(output_path)
    
    # Verificar que el DataFrame se ha cargado correctamente
    print("El archivo CSV se ha leído correctamente en un DataFrame de pandas.")
    display(bbdd.head())  # Mostrar las primeras filas del DataFrame para verificar
else:
    print("Error en la descarga del archivo")
#------------------------------------------------------------------------------------------------------------------------------------------------------------------
import numpy as np
bbdd['log_F_AMOUNT_TRANSACTION'] = np.log1p(bbdd['F_AMOUNT_TRANSACTION'])
bbdd['log_F_AMOUNT_TRANSACTION'] = bbdd['log_F_AMOUNT_TRANSACTION'].astype('float64')

bbdd['log_MONTO_PROM_ULT_MES'] = np.log1p(bbdd['MONTO_PROM_ULT_MES'])
bbdd['log_MONTO_PROM_ULT_MES'] = bbdd['log_MONTO_PROM_ULT_MES'].astype('float64')

bbdd['log_MONTO_PROM_ULT_MES_ENTRY'] = np.log1p(bbdd['MONTO_PROM_ULT_MES_ENTRY'])
bbdd['log_MONTO_PROM_ULT_MES_ENTRY'] = bbdd['log_MONTO_PROM_ULT_MES_ENTRY'].astype('float64')

bbdd['log_MONTO_PROM_ULT_MES_MERCHANT'] = np.log1p(bbdd['MONTO_PROM_ULT_MES_MERCHANT'])
bbdd['log_MONTO_PROM_ULT_MES_MERCHANT'] = bbdd['log_MONTO_PROM_ULT_MES_MERCHANT'].astype('float64')

bbdd['log_last_transaction_amount'] = np.log1p(bbdd['last_transaction_amount'])
bbdd['log_last_transaction_amount'] = bbdd['log_last_transaction_amount'].astype('float64')
#------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Columnas a eliminar
columns_to_remove = ['PERIODO', 'ID_TRX','N_ID_CUSTOMER','S_CARD_ACCEPT_EXT_ID_CODE',
                     'F_AMOUNT_TRANSACTION','D_TRANSMISSION_DATE_AND_TIME',
                     'S_RESPONSE_CODE','NUMERO_DOCUMENTO_CODIFICADO',
                     'S_PAN','S_PAN_CODIFICADO','MONTO_PROM_ULT_MES','MONTO_PROM_ULT_MES_ENTRY'
                      'MONTO_PROM_ULT_MES_MERCHANT','last_transaction_amount']

# Método 1: List Comprehension
filtered_columns = [col for col in bbdd.columns if col not in columns_to_remove]
#------------------------------------------------------------------------------------------------------------------------------------------------------------------
bbdd['time_since_last_transaction'] = bbdd['time_since_last_transaction'].fillna(0)
bbdd['log_last_transaction_amount'] = bbdd['log_last_transaction_amount'].fillna(0)
bbdd['CANT_CLI_DISPOSITIVO'] = bbdd['CANT_CLI_DISPOSITIVO'].fillna(0)
#------------------------------------------------------------------------------------------------------------------------------------------------------------------
for col in filtered_columns:
    if 'int' in str(bbdd[col].dtype):
        bbdd[col] = bbdd[col].astype('int64')
    elif 'float' in str(bbdd[col].dtype):
        bbdd[col] = bbdd[col].astype('float64')

#------------------------------------------------------------------------------------------------------------------------------------------------------------------
import pandas as pd
import numpy as np

# Suponiendo que tienes tu dataset cargado en un DataFrame llamado df
# Asegúrate de preparar tus datos adecuadamente según las características específicas de tu dataset

# Usar dask para manejar grandes volúmenes de datos
# import dask.dataframe as dd

# Convertir pandas DataFrame a dask DataFrame
# ddf = dd.from_pandas(bbdd[filtered_columns], npartitions=1)  # Aumentar npartitions si es necesario

# Separar características (X) y etiquetas (y)
X = bbdd[filtered_columns].drop('fraude', axis=1)
y = bbdd[filtered_columns]['fraude']

# Convertir dask DataFrame a pandas DataFrame por particiones para el muestreo
# X = X.compute()
# y = y.compute()

# Aplicar NearMiss en partes para manejar la memoria
chunk_size = 1000000  # Ajusta este tamaño según la memoria disponible
num_chunks = int(np.ceil(len(X) / chunk_size))
num_chunks

------------------------------------------------------------------------------------------------------------------------------------------------------------------
import gc
del bbdd
gc.collect()


------------------------------------------------------------------------------------------------------------------------------------------------------------------
